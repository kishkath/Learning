{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIhd9cU3bBdO"
   },
   "source": [
    "![picture](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSuFVuyj1Yve"
   },
   "source": [
    "## Python lists or tuples of numbers are collections of Python objects that are individually allocated in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-eq-Mpaz0rt",
    "outputId": "69e32463-3c26-4bde-a942-f9b35e66cdf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# first let's define a list and see the size it occupies\n",
    "a = [1.0, 2.0, 3.0]\n",
    "print(type(a))\n",
    "print(a.__sizeof__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9l8OtaJU71"
   },
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRCctAw3JIaO"
   },
   "outputs": [],
   "source": [
    "# define a list of integers and see the size it occupies\n",
    "# print exactly like we did in previous cell\n",
    "## code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGjH5xX_3KYa"
   },
   "source": [
    "## PyTorch tensors or NumPy arrays, on the other hand, are views over typically) contiguous memory blocks containing unboxed C numeric types rather than Python objects. Each element is 32 bit (4-byte for 32 bit and 8 byte for 64 bit in general)  float in this case used in pytorch by default. This means storing a 1D tensor of 1000,000 float numbers will require exactly 4,000,000 contiguous bytes, plus a small overhead for the metadata (such as dimensions and numeric type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiOUDgYL0uxl",
    "outputId": "3087f3a9-3188-49cc-c494-7b366eaf9f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [1. 2. 3.], and it's dtype: float64\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "print(\"a: {}, and it's dtype: {}\".format(a, a.dtype))\n",
    "print(a.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAWe0k8U1_Sm",
    "outputId": "c645b37c-62e0-408a-9777-8077abfcaad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1., 1., 1.]), and it's dtpe: torch.float32\n",
      "size:  12\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.ones(3)\n",
    "print(\"a: {}, and it's dtpe: {}\".format(a, a.dtype))\n",
    "print(\"size: \", a.element_size()*a.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3y7jXac8-PR",
    "outputId": "b2a58f4b-190e-46cf-96d7-eb2ac30c8a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can create a tensor of zeros and replace it's values\n",
    "my_tensor = t.zeros((3, 2))\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw-bBT8m4LaC"
   },
   "outputs": [],
   "source": [
    "# replace it's zeros with 1., 2., 3., 4., 5., 6.\n",
    "my_tensor[0, 0] = 1.\n",
    "my_tensor[0, 1] = 2.\n",
    "my_tensor[1, 0] = 3.\n",
    "my_tensor[1, 1] = 4.\n",
    "my_tensor[2, 0] = 5.\n",
    "my_tensor[2, 1] = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mxPPS_W9fMd",
    "outputId": "c09c5cfe-0712-4691-c92e-db01bb264b68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print my_tensor\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emf5no8GJonP"
   },
   "source": [
    "**Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lc-LW66WJnoY"
   },
   "outputs": [],
   "source": [
    "# create a tensor of ones with size (5,5) and replace each element's values with any value you like\n",
    "# then print the tensor\n",
    "## code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCPvfU8M9gtm",
    "outputId": "364d868d-8617-401c-d159-2a8a4f91c88c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can pass lists of list to create a tensor\n",
    "two_D_tensor = t.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "two_D_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C82mOnQpKR_x"
   },
   "source": [
    "**Task 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMmAJjuyKYCL"
   },
   "outputs": [],
   "source": [
    "# create a list of lists and pass into t.tensor and print your tensor\n",
    "## code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZWvavNy_jt6",
    "outputId": "91960927-93a7-45ac-e860-9e8acf987838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1811, -0.8786,  0.5294],\n",
       "         [-1.5866,  0.4524, -0.9706],\n",
       "         [-1.7160, -0.0160, -0.0269],\n",
       "         [-1.7133,  0.4381,  0.0043]],\n",
       "\n",
       "        [[-0.1985, -1.1853, -0.5703],\n",
       "         [-1.7658,  0.6095,  0.5504],\n",
       "         [-0.5733, -1.4506, -0.2268],\n",
       "         [ 2.0636,  0.9851, -0.5847]],\n",
       "\n",
       "        [[-0.2807, -0.8224,  0.0069],\n",
       "         [ 0.0397, -0.9972, -0.8684],\n",
       "         [ 0.9302, -0.6041,  0.7761],\n",
       "         [-0.1464, -1.4105,  0.1765]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating 3-d tensor\n",
    "random_tensor = t.randn((3,4,3)) # here 3,4,3 ---> refers channels, rows, columns\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y35wGm_hANv_",
    "outputId": "494bb6b3-1fbd-47dd-f81a-47a840ad1565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 4th row last element of first (4,3) matrix:  tensor(0.0043)\n",
      "Printing 1st row first element of second (4,3) matrix:  tensor(-0.1985)\n",
      "Printing 2nd row 2nd element of second (4,3) matrix:  tensor(0.6095)\n",
      "Printing 4th row first element of last (4,3) matrix:  tensor(-0.1464)\n"
     ]
    }
   ],
   "source": [
    "# indexing tensors\n",
    "print(\"Printing 4th row last element of first (4,3) matrix: \", random_tensor[0][3][2])\n",
    "print(\"Printing 1st row first element of second (4,3) matrix: \", random_tensor[1][0][0])\n",
    "print(\"Printing 2nd row 2nd element of second (4,3) matrix: \", random_tensor[1][1][1])\n",
    "print(\"Printing 4th row first element of last (4,3) matrix: \", random_tensor[2][3][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViNAhwBJLc1P"
   },
   "source": [
    "**Task 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8Ah7B0o88WO"
   },
   "outputs": [],
   "source": [
    "# Print 3rd row last element of first (4,3) matrix\n",
    "# Print 2nd row first element of second (4,3) matrix\n",
    "# Print 1st row 2nd element of first (4,3) matrix\n",
    "# Print 1st row first element of last (4,3) matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg1q9u7GK3b4"
   },
   "source": [
    "**Task 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEjgH3MwK7-T"
   },
   "outputs": [],
   "source": [
    "# create a 3d tensor of channels=5, rows=6, columns=3\n",
    "## print your tensor and try to access each element with indexing like we did above\n",
    "## code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6is1sthCeq8",
    "outputId": "b050feed-5c98-47f3-eed5-f846bb0bf948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        [100, 100, 100]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with a fixed value for every element\n",
    "fixed_tensor = t.full((3, 3), 100)\n",
    "fixed_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBnlGS3bMgkZ"
   },
   "source": [
    "**Task 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmYuwzWtMlck"
   },
   "outputs": [],
   "source": [
    "# create a tensor of shape of your choice and fill with value 50 like we did above\n",
    "# print your tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5P_00ryCetH",
    "outputId": "04870c17-cc91-42e9-8f39-fdd44906e772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        [ 50,  50,  50],\n",
       "        [ 50,  50,  50],\n",
       "        [ 50,  50,  50]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate two tensors with compatible shapes\n",
    "concat_tensor = t.cat((fixed_tensor, t.full((3,3), 50)))\n",
    "concat_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX9Wmh0MM4yl"
   },
   "source": [
    "**Task 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mtmpFgQM8TP"
   },
   "outputs": [],
   "source": [
    "# create two tensors of your favorite shape and concatenate them using t.cat as we did above\n",
    "# print both tensor before concatenation and also print concatenated tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ospFZfrKCevQ",
    "outputId": "6e12aa2e-3821-427d-aaeb-d371880c3b68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100, 100],\n",
       "         [100, 100],\n",
       "         [100, 100]],\n",
       "\n",
       "        [[100, 100],\n",
       "         [100,  50],\n",
       "         [ 50,  50]],\n",
       "\n",
       "        [[ 50,  50],\n",
       "         [ 50,  50],\n",
       "         [ 50,  50]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the shape of a tensor\n",
    "reshaped = concat_tensor.reshape(3, 3, 2)\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUj_uqJwVxsm"
   },
   "source": [
    "**Task 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHqL1oKAV1zd"
   },
   "outputs": [],
   "source": [
    "# create a tensor of shape (5,4,2) and then reshape it into some other dimension of your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVQewuYTCeyE",
    "outputId": "30a0eca4-3d05-4f67-d8a1-9cd7d02f15c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensor from numpy array\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "array_to_tensor = t.from_numpy(x)\n",
    "array_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LByHq5-JEcp",
    "outputId": "4f988865-ecdc-41b4-8370-1a3c310a3003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "tensor_to_array = array_to_tensor.numpy()\n",
    "tensor_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZolGJ8nWIiW"
   },
   "source": [
    "**Task 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKzDH-eEWI0h"
   },
   "outputs": [],
   "source": [
    "# create a 2-D numpy array of your choice and then convert into tensor using from_numpy and convert tensor back to array using .numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UO7nLHZTg59t",
    "outputId": "e7f0b14b-bdfb-460b-aec4-3895ff63a664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 17],\n",
       "        [26, 41]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplying tensors\n",
    "a = t.tensor([[1,2,3], [4,5,6]]) # observe the shape (2,3)\n",
    "b = t.tensor([[0,1], [4,5], [1,2]]) # observe the shape (3,2)\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhiDt_7uWjDb"
   },
   "source": [
    "**Task 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eCkFwcpWjPk"
   },
   "outputs": [],
   "source": [
    "# create two tensors like we did above and multiply them using matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBr-fo9oiFVg"
   },
   "outputs": [],
   "source": [
    "# check it's documentation\n",
    "? t.linalg.matrix_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tA0ptdviiEk",
    "outputId": "54de2ce6-cec6-4b75-f232-6d126468c714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq matrix:  tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compute nth power of a square matrix\n",
    "sq_matrix = t.ones((2,2))\n",
    "print(\"sq matrix: \", sq_matrix)\n",
    "t.linalg.matrix_power(sq_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh2rEztC9wHE"
   },
   "source": [
    "**Tensor Operations and How to do Gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qr3yj7A9noj",
    "outputId": "a3f9d3be-f35b-4a2e-f499-c57ee38742b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(4., requires_grad=True), tensor(3., requires_grad=True))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = t.tensor(7.)\n",
    "w = t.tensor(4., requires_grad=True)\n",
    "b = t.tensor(3., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpHnQIcn-OfI",
    "outputId": "a8e213fa-48ef-4d5f-8bf2-56aa03772f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the equation by arithmetic operation\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zra92KNi_Un3"
   },
   "outputs": [],
   "source": [
    "# Computing derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVbuErRw_oOT",
    "outputId": "dff6d2c2-5fa6-4110-f78a-da441b6cfdc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(7.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jnqoQ54XtbU"
   },
   "source": [
    "As expected, `dy/dw` has the same value as `x`, i.e., `7`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`. \n",
    "\n",
    "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tEzio1iYUi4"
   },
   "source": [
    "**Task 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeelhMquYXkb"
   },
   "outputs": [],
   "source": [
    "# create 3 tensors x,w,b of your choice and then compute y=w*x + b. After defining y, compute gradients like we did in previous steps.\n",
    "# observe all the steps of tensor operations and gradients. Look into the documentation of tensor if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igQ6jkGeGVt5"
   },
   "source": [
    "**Task 12**\n",
    "\n",
    "Understand the whole Linear Regression From Scratch in next section. Then implement the same by taking input as area of the house and output as price of the house. You can take some random inputs of your own choice just like we did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-az-tKzpjsV"
   },
   "source": [
    "**Linear Regression From Scratch**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmD3erUL4APO"
   },
   "source": [
    "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "\n",
    "```\n",
    "percent  = w11 * maths + w12 * physics + w13 * chemistry + b1\n",
    "\n",
    "```\n",
    "\n",
    "![linear-regression-graph](https://i.stack.imgur.com/O5036.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJHNB0iapap5"
   },
   "outputs": [],
   "source": [
    "# Here i'm taking marks of maths, physics, chemistry as input and i'm creating an array of it\n",
    "marks = np.array([[60, 70, 75],\n",
    "                  [70, 75, 80],\n",
    "                  [70, 72, 77],\n",
    "                  [90, 91, 95],\n",
    "                  [95, 95, 99],\n",
    "                  [50, 60, 65]], dtype='float32')\n",
    "\n",
    "# target is percentage which a person will get\n",
    "percent = np.array([68.3, 75.0, 76.3, 92.0, 96.3, 58.3], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfCHK17hpasI",
    "outputId": "f2755ccb-5a07-4ec0-f81b-ae790a4a7fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[60., 70., 75.],\n",
      "        [70., 75., 80.],\n",
      "        [70., 72., 77.],\n",
      "        [90., 91., 95.],\n",
      "        [95., 95., 99.],\n",
      "        [50., 60., 65.]])\n",
      "tensor([68.3000, 75.0000, 76.3000, 92.0000, 96.3000, 58.3000])\n"
     ]
    }
   ],
   "source": [
    "# converting array into tensor\n",
    "marks = t.from_numpy(marks)\n",
    "percent = t.from_numpy(percent)\n",
    "\n",
    "# printing marks and percentage both\n",
    "print(marks)\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOGc9yEj7mM-"
   },
   "source": [
    "The weights and biases (w11, w12,... w23, b1 & b2) can also be represented as matrices, initialized as random values. The first row of w and the first element of b are used to predict the first target variable which is percent.\n",
    "\n",
    "Notice, our input is having 3 features, and output is 1, so our weight will be (1,3) shape and bias will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLLF7R6tpauw",
    "outputId": "cf11f8b1-eb04-496a-9f43-896ee0194196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0187], requires_grad=True)\n",
      "tensor([[ 2.8057, -0.3628, -1.2635]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# creating weights and biases using randn function\n",
    "marks_wt = t.randn(1, 3, requires_grad=True)\n",
    "marks_bias = t.randn(1, requires_grad=True)\n",
    "print(marks_bias)\n",
    "print(marks_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qugl5wPcpaxl"
   },
   "outputs": [],
   "source": [
    "# creating the model\n",
    "#  @ represents matrix multiplication in PyTorch, and the .t method returns the transpose of a tensor.\n",
    "def marks_model(x):\n",
    "  return x @ marks_wt.t() + marks_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wykz91mvqR1y",
    "outputId": "d93a4f37-9321-4271-e8e3-149f53da6a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 48.1662],\n",
      "        [ 68.0918],\n",
      "        [ 72.9706],\n",
      "        [ 99.4489],\n",
      "        [106.9723],\n",
      "        [ 36.3720]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "percent_pred = marks_model(marks)\n",
    "print(percent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w38jLYZiqR4j",
    "outputId": "608b36ab-e2a1-4993-8700-ad42faf55eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([68.3000, 75.0000, 76.3000, 92.0000, 96.3000, 58.3000])\n"
     ]
    }
   ],
   "source": [
    "# Compare with percent\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82LLmuB8qfeW"
   },
   "source": [
    "You can see a big difference between our model's predictions and the actual targets because we've initialized our model with random weights and biases. Obviously, we can't expect a randomly initialized model to just work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQ-WJN4x9qAm"
   },
   "source": [
    "## Loss function\n",
    "\n",
    "How to define a loss function ?\n",
    "\n",
    "\n",
    "* Calculate the difference between the two matrices (`marks` and `percent`).\n",
    "* Square all elements of the difference matrix to remove negative values.\n",
    "* Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "You will get in the end,  **mean squared error** (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aR5Soo8kqZ2e"
   },
   "outputs": [],
   "source": [
    "# t.sum returns the sum of all the elements in a tensor. \n",
    "# The .numel method of a tensor returns the number of elements in a tensor. \n",
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return t.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Kzx3d5tqZ5Q",
    "outputId": "af613abd-9696-4879-9a88-22e3f17da97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(841.5394, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's check the loss\n",
    "percent_loss = mse(percent_pred, percent)\n",
    "print(percent_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q15ME5KyrVsz"
   },
   "source": [
    "Here’s how we can interpret the result: On average, each element in the prediction differs from the actual target by the square root of the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcRJQNP1rVz0"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Compute gradients\n",
    "\n",
    "With PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases because they have requires_grad set to True. We'll see how this is useful in just a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4a_otlsrYFw"
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "percent_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EKbOsqOrfl0",
    "outputId": "531a29b1-b4e1-44e0-918d-c0438ddaa363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8057, -0.3628, -1.2635]], requires_grad=True)\n",
      "tensor([[ -34.6004, -282.7236, -356.6945]])\n"
     ]
    }
   ],
   "source": [
    "# check weights and it's gradient\n",
    "print(marks_wt)\n",
    "print(marks_wt.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-6C8NdQ_0If"
   },
   "source": [
    "## How to adjust weights and biases to reduce the loss?\n",
    "\n",
    "If a gradient element is **positive**:\n",
    "\n",
    "* **increasing** the weight element's value slightly will **increase** the loss, and will go towards local maxima.\n",
    "* **decreasing** the weight element's value slightly will **decrease** the loss and will go towards local minima.\n",
    "\n",
    "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)\n",
    "\n",
    "If a gradient element is **negative**:\n",
    "\n",
    "\n",
    "* **increasing** the weight element's value slightly will **decrease** the loss, will go towards local minima.\n",
    "* **decreasing** the weight element's value slightly will **increase** the loss, will go towards local maxima.\n",
    "\n",
    "![negative=gradient](https://i.imgur.com/dvG2fxU.png)\n",
    "\n",
    "In 3-D, local minima and global minima will look like this: \n",
    "![3-D=gradient](https://blog.paperspace.com/content/images/2018/05/challenges-1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnDoGCB7rfoj"
   },
   "outputs": [],
   "source": [
    "# We can subtract from each weight element a small quantity proportional to the derivative of the loss w.r.t. that element to reduce the loss slightly.\n",
    "with t.no_grad():\n",
    "\n",
    "    marks_wt -= marks_wt.grad * 1e-5\n",
    "    marks_bias -= marks_bias.grad * 1e-5\n",
    "    marks_wt.grad.zero_() # note this step of resetting the gradient to zero\n",
    "    marks_bias.grad.zero_() # We need to do this because PyTorch accumulates gradients, which may lead to unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQtgueLAr_Mp"
   },
   "source": [
    "Here 1e-5 is the learning rate.\n",
    "We multiply the gradients with a very small number (10^-5 in this case) to ensure that we don't modify the weights by a very large amount. We want to take a small step in the downhill direction of the gradient, not a giant leap. This number is called the learning rate of the algorithm.\n",
    "\n",
    "We use torch.no_grad to indicate to PyTorch that we shouldn't track, calculate, or modify gradients while updating the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6rN580bsAc9",
    "outputId": "2e30c92f-ba23-45bc-e365-20759a7370fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(839.7478, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "percent_pred = marks_model(marks)\n",
    "percent_loss = mse(percent_pred, percent)\n",
    "print(percent_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlyKOiDHsJjh"
   },
   "source": [
    "Before we proceed, we reset the gradients to zero by invoking the .zero_() method. We need to do this because PyTorch accumulates gradients. Otherwise, the next time we invoke .backward on the loss, the new gradient values are added to the existing gradients, which may lead to unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WFmmDK8sII6",
    "outputId": "9695ce71-9cdc-42cb-f0a5-a798c05cf8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# You can check if gradients are set to zero or not\n",
    "print(marks_wt.grad)\n",
    "print(marks_bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjTgkqgLbr0S"
   },
   "source": [
    "## Training the model with these steps:\n",
    "\n",
    "\n",
    "1) Generating predictions\n",
    "\n",
    "2) Calculating the loss\n",
    "\n",
    "3) Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4) Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5) Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVGxZBpIbuLa",
    "outputId": "8df21eaa-5270-481c-e519-b76e680a39ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 48.6525],\n",
      "        [ 68.6135],\n",
      "        [ 73.4732],\n",
      "        [100.0763],\n",
      "        [107.6270],\n",
      "        [ 36.7909]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "percent_pred = marks_model(marks)\n",
    "print(percent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aU5RU5Y1cWwn",
    "outputId": "9cde6794-1357-4ddf-9978-b24aaba6d310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(839.7478, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "percent_loss = mse(percent_pred, percent)\n",
    "print(percent_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdotRts-ckPA",
    "outputId": "24d95143-a304-4a65-900c-b3598d16201c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  45.5616, -198.1306, -267.1762]])\n",
      "tensor([-10.3223])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients and print gradients of weight and bias\n",
    "percent_loss.backward()\n",
    "print(marks_wt.grad)\n",
    "print(marks_bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25Hbxg-sdEG7"
   },
   "source": [
    "Let's update the weights and biases using the gradients computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I6kOI4ac4VC"
   },
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with t.no_grad():\n",
    "    marks_wt -= marks_wt.grad * 1e-5\n",
    "    marks_bias -= marks_bias.grad * 1e-5\n",
    "    marks_wt.grad.zero_()\n",
    "    marks_bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bza9Se6tdX5L",
    "outputId": "5d68de62-e6ae-4df3-b763-4a8da01ae4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8056, -0.3580, -1.2573]], requires_grad=True)\n",
      "tensor([-0.0185], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# looking at new weight and bias\n",
    "print(marks_wt)\n",
    "print(marks_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNhR3_hvdLvi"
   },
   "source": [
    "With the new weights and biases, the model should have a lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJUdUR_gdKs8",
    "outputId": "564e5d19-a717-4b85-81d2-fad9b05c774d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(838.7366, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = marks_model(marks)\n",
    "loss = mse(preds, percent)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zOsPU2-dhZD"
   },
   "source": [
    "We have achieved a little reduction in the loss merely by adjusting the weights and biases slightly using gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD6E_L5Fdupd"
   },
   "source": [
    "To reduce the loss further, we can repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch. Let's train the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94Urmas6dnBs"
   },
   "outputs": [],
   "source": [
    "# training for multiple epochs\n",
    "\n",
    "for i in range(150):\n",
    "  percent_pred = marks_model(marks)\n",
    "  percent_loss = mse(percent_pred, percent)\n",
    "  percent_loss.backward()\n",
    "  with t.no_grad():\n",
    "    marks_wt -= marks_wt.grad * 1e-5\n",
    "    marks_bias -= marks_bias.grad * 1e-5\n",
    "    marks_wt.grad.zero_()\n",
    "    marks_bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4NbSRBud3jc",
    "outputId": "c1009600-a701-4fbb-ce02-b9028ecfc152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(706.0983, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate loss\n",
    "\n",
    "percent_pred = marks_model(marks)\n",
    "percent_loss = mse(percent_pred, percent)\n",
    "print(percent_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj_Rlutdd9k5"
   },
   "source": [
    "The loss is now much lower than its initial value. Let's look at the model's predictions and compare them with the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxOqoxd7eCE2",
    "outputId": "205610e4-7dfb-49f1-edc2-d9078ec0a389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 53.1078],\n",
      "        [ 70.3147],\n",
      "        [ 73.7257],\n",
      "        [ 98.8381],\n",
      "        [105.7360],\n",
      "        [ 41.5860]], grad_fn=<AddBackward0>)\n",
      "tensor([68.3000, 75.0000, 76.3000, 92.0000, 96.3000, 58.3000])\n"
     ]
    }
   ],
   "source": [
    "# result is good and we can make it better with more epochs\n",
    "print(percent_pred)\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9H7Cr6mSaGa"
   },
   "source": [
    "**FEEDBACK FORM**\n",
    "\n",
    "Please help us to improve by filling this form.\n",
    "https://forms.zohopublic.in/cloudyml/form/CloudyMLDeepLearningFeedbackForm/formperma/VCFbldnXAnbcgAIl0lWv2blgHdSldheO4RfktMdgK7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLhxz4T2HUzF"
   },
   "source": [
    "![](https://images.freeimages.com/images/large-previews/737/track-finish-1442273.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw77TkgDIA6F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_fundamentals.ipynb",
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}